{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/psterritt5/biographical-parser/blob/main/biographical_parser_gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjqy7heO706G"
      },
      "source": [
        "# Project description\n",
        "In this project I used GPT-3.5-turbo to transform unstructured data in the form of a biography to structured data in the form of attribute-value pairs. Given a Wikipedia Biograph like this:\n",
        "\n",
        "> Jill Tracy Jacobs Biden (born June 3, 1951) is an American educator and the current first lady of the United States as the wife of President Joe Biden. She was the second lady of the United States from 2009 to 2017. Since 2009, Biden has been a professor of English at Northern Virginia Community College.\n",
        "\n",
        "> She has a bachelor's degree in English and a doctoral degree in education from the University of Delaware, as well as master's degrees in education and English from West Chester University and Villanova University. She taught English and reading in high schools for thirteen years and instructed adolescents with emotional disabilities at a psychiatric hospital. From 1993 to 2008, Biden was an English and writing instructor at Delaware Technical & Community College. Biden is thought to be the first wife of a vice president or president to hold a paying job during her husband's tenure.\n",
        "\n",
        "> Born in Hammonton, New Jersey, she grew up in Willow Grove, Pennsylvania. She married Joe Biden in 1977, becoming stepmother to Beau and Hunter, his two sons from his first marriage. Biden and her husband also have a daughter together, Ashley Biden, born in 1981. She is the founder of the Biden Breast Health Initiative non-profit organization, co-founder of the Book Buddies program, co-founder of the Biden Foundation, is active in Delaware Boots on the Ground, and with Michelle Obama is co-founder of Joining Forces. She has published a memoir and two children's books.\n",
        "\n",
        "I created models that would output structured data like:\n",
        "```\n",
        "notable_type: First Lady of the United States\n",
        "name: Jill Biden\n",
        "gender: female\n",
        "nationality: American\n",
        "birth_date: 03 June 1951\n",
        "birth_place: Hammonton, New Jersey\n",
        "alma_mater: University of Delaware\n",
        "occupation: professor of English at Northern Virginia Community College\n",
        "notable_works: children's books and memoir\n",
        "main_interests: education, literacy, women's health\n",
        "partner: Joe Biden\n",
        "children: Ashley Biden, Beau Biden (stepson), Hunter Biden (stepson)\n",
        "```\n",
        "\n",
        "To accomplish this I used the following strategies:\n",
        "\n",
        "\n",
        "*   Zero shot learning\n",
        "*   Few shot learning\n",
        "*   Fine-tuned models\n",
        "\n",
        "Then measured and compared performance on 3 metrics (recall, precision and f-scores) using a seperate test set."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you would like to run my code, you may enter your API key below. If you have an OpenAI account, you can generate an API key [here](https://platform.openai.com/api-keys).  "
      ],
      "metadata": {
        "id": "P4LPmPmEL_Pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%pip install --upgrade openai\n",
        "%pip install jsonlines\n",
        "%pip install wandb"
      ],
      "metadata": {
        "id": "x-APaRcDAXcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PIBX87qrlDd",
        "outputId": "6175cb7a-9f89-4bc6-b129-833b6822f67c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenAI API key:\n",
            "··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "import openai\n",
        "import os\n",
        "\n",
        "print('Enter OpenAI API key:')\n",
        "openai.api_key = getpass()\n",
        "\n",
        "os.environ['OPENAI_API_KEY']=openai.api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load training data & lightly process\n",
        "Take 200 random samples from the training dataset. When fine-tuning we will use an 80/20 ratio with 200 samples from the training dataset and 50 samples from the test set. This data is mostly intended for fine-tuning, but we will also use a few examples to prompt the few-shot learning model. Processing includes slight reformattting; additional processing will be required for fine-tuning."
      ],
      "metadata": {
        "id": "KmP3UGDzQDP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/artificial-intelligence-class/artificial-intelligence-class.github.io/master/homeworks/large-LMs/SynthBio_train.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rc0GiAGQJuX",
        "outputId": "cdf3b2b3-0025-46c6-f4f1-961587c61258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-14 12:59:30--  https://raw.githubusercontent.com/artificial-intelligence-class/artificial-intelligence-class.github.io/master/homeworks/large-LMs/SynthBio_train.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5807118 (5.5M) [text/plain]\n",
            "Saving to: ‘SynthBio_train.json.1’\n",
            "\n",
            "SynthBio_train.json 100%[===================>]   5.54M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2024-08-14 12:59:30 (121 MB/s) - ‘SynthBio_train.json.1’ saved [5807118/5807118]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a file called 'SynthBio_train.json' which is a list of json objects.\n",
        "\n",
        "import json\n",
        "import random\n",
        "\n",
        "def load_wiki_bio_data(filename='SynthBio_train.json', num_bios=200, randomized=True):\n",
        "  with open(filename) as f:\n",
        "    synth_bio_data = json.load(f)\n",
        "  if randomized:\n",
        "    random.shuffle(synth_bio_data)\n",
        "  bios = []\n",
        "  for data in synth_bio_data:\n",
        "    notable_type = data['notable_type']\n",
        "    attributes = \"notable_type: {notable_type} | {other_attributes}\".format(\n",
        "        notable_type = notable_type,\n",
        "        other_attributes = data['serialized_attrs']\n",
        "    )\n",
        "    biography = data['biographies'][0]\n",
        "    bios.append((attributes.replace(\" | \", \"\\n\"), biography))\n",
        "  print('There are ' + str(len(bios)) + ' samples in the training dataset.')\n",
        "  return bios[:min(num_bios, len(bios))]\n",
        "\n",
        "wiki_bios = load_wiki_bio_data()\n",
        "attributes, bio = wiki_bios[0]\n",
        "print(attributes)\n",
        "print('---')\n",
        "bio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "9a3OjTA-QU2G",
        "outputId": "0c00001c-2f67-44ad-9f3c-856e53ba0914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2000 samples in the training dataset.\n",
            "notable_type: musician\n",
            "name: Albeto Hernandez\n",
            "birth_name: José Antonio Domínguez\n",
            "alias: The Black-Skinned Angel\n",
            "gender: non-binary\n",
            "birth_date: 25 May 1866\n",
            "birth_place: Puerto Plata, Dominican Republic\n",
            "death_date: March 28, 1921\n",
            "death_place: Santiago, Santiago Province, Dominican Republic\n",
            "death_cause: flu\n",
            "resting_place: Cementario Municipal Santiago\n",
            "instrument: guitar\n",
            "genre: folk\n",
            "hometown: Puerto Plata, Dominican Republic\n",
            "nationality: Dominican\n",
            "citizenship: Dominican Republic\n",
            "years_active: 1883-1921\n",
            "label: Black Angel\n",
            "associated_acts: Black Angel Orchestra\n",
            "awards: Grammy Award (1999), Latin Grammy Award (2006)\n",
            "mother: Mariana Solano\n",
            "father: Antonio Hernandez\n",
            "partner: Adela Hernandez\n",
            "---\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'José Antonio Domínguez (25 May 1866 – 28 March 1921) was born in Puerto Plata, Dominican Republic. He was known as \"Black-Skinned Angel\". He was born to Antonio Hernandez and Mariana Solano. Their Awards are Grammy Award (1999), Latin Grammy Award (2006). His label was Black Angel and associated acts are Black Angel Orchestra. He was active between 1883-1921. They were married to Adela Hernandez. He died in Santiago in 25 May,1921. He died in 1921 in Santiago de los Caballeros. He was buried in the Municipal Cemetery of Santiago.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero shot learning\n",
        "\n",
        "Attempt to create a biographical parser using GPT-3.5-turbo using only zero-shot prompting."
      ],
      "metadata": {
        "id": "lYxpAr8hPoUl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "XWEc9393Sp55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_bio_zero_shot(bio, *args):\n",
        "  system_message = {\"role\" : \"system\", \"content\" : (\"Given a biography, output a set of attributes and attribute values.\"\n",
        "                                                    \"Use the strict format attribute_type: attribute_value.\")}\n",
        "\n",
        "  client = openai.OpenAI()\n",
        "  response = client.chat.completions.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages= [\n",
        "          system_message,\n",
        "          {\"role\" : \"user\", \"content\" : bio + \"###\"}\n",
        "      ],\n",
        "      temperature=0.7,\n",
        "      max_tokens=512,\n",
        "      top_p=1,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0,\n",
        "      stop=[\"###\"]\n",
        "  )\n",
        "  return response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "NwoxHi65dTjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single Test\n",
        "\n",
        "We will use a more rigorous test set later. For now, lets verify this zero-shot model is able to provide coherent feedback."
      ],
      "metadata": {
        "id": "pTYpBmZJSsX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "biography = str(wiki_bios[0][1])\n",
        "attributes = parse_bio_zero_shot(biography)\n",
        "print(biography)\n",
        "print('---')\n",
        "print(attributes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpritqCESwai",
        "outputId": "c37cb2ea-6f40-45fb-9f3d-6b9d7ded65b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eshan Zaidi (born March 7, 1947) is a retired Qatari hammer thrower. He competed at the 1976 and 1984 Summer Olympics and the 1986 Asian Games. Al Zaidi won the gold medal at the 1982 Asian Games, and silver medals at the 1978 and 1982 Asian Games and 1976 and 1984 Summer Olympics. He also won the 1985 and 1986 Asian Athletics Championships. Zaidi is the second person to throw hammer more than 200 meters. Al Zaidi had a personal best of , which is the Qatari national record. His mother and father are Abdullah al Zaidi,Um Abdullah (née Fahad). He is married to Lea al Sallam.\n",
            "---\n",
            "- Name: Eshan Zaidi\n",
            "- Date of Birth: March 7, 1947\n",
            "- Nationality: Qatari\n",
            "- Occupation: Retired hammer thrower\n",
            "- Olympic Appearances: 1976, 1984\n",
            "- Asian Games Appearances: 1986, 1978, 1982\n",
            "- Gold Medals: 1982 Asian Games\n",
            "- Silver Medals: 1978 Asian Games, 1982 Asian Games, 1976 Summer Olympics, 1984 Summer Olympics\n",
            "- Asian Athletics Championships: 1985, 1986\n",
            "- Hammer Throw Personal Best: 200 meters\n",
            "- National Record: Qatari\n",
            "- Parents: Abdullah al Zaidi, Um Abdullah (née Fahad)\n",
            "- Spouse: Lea al Sallam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Few shot learning\n",
        "\n",
        "Try to improve upon the results obtained using zero shot learning using few shot learning."
      ],
      "metadata": {
        "id": "Uv7pCdc8ckQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "Dd6XtgBPS3e_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import os\n",
        "import time\n",
        "\n",
        "def parse_bio_few_shot(bio, *args):\n",
        "  ''' few shot prompt = 3 examples from training set in the format:\n",
        "      {wiki bio} \\n---\\n {attributes}'''\n",
        "  few_shot_prompt = \"\"\n",
        "  for i in range(1,4):\n",
        "    few_shot_prompt += wiki_bios[i][1] +'\\n---\\n' + wiki_bios[i][0]\n",
        "  few_shot_prompt += '\\n---\\n'\n",
        "\n",
        "  system_message = {\"role\" : \"system\", \"content\" : \"You should recognize a pattern in the prompts and generate a completion based on that pattern.\"}\n",
        "\n",
        "  client = openai.OpenAI()\n",
        "  response = client.chat.completions.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages= [\n",
        "          system_message,\n",
        "          {\"role\" : \"user\", \"content\" : few_shot_prompt + bio + \"\\n---### \"} # simulate a user prompt\n",
        "      ],\n",
        "      temperature=0.7,\n",
        "      max_tokens=1024, # increased num tokens due to length of prompt\n",
        "      top_p=1,\n",
        "      frequency_penalty=0,\n",
        "      presence_penalty=0,\n",
        "      stop=[\"###\"]\n",
        "  )\n",
        "  # I recommend putting a short wait after each call,\n",
        "  # since the rate limit for the platform is 60 requests/min.\n",
        "  # (This increases to 3000 requests/min after you've been using the platform for 2 days).\n",
        "  time.sleep(1)\n",
        "\n",
        "  # the response from OpenAI's API is a JSON object that contains\n",
        "  # the completion to your prompt plus some other information.  Here's how to access\n",
        "  # just the text of the completion.\n",
        "  return response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "mn3lrsR9nt6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single Test"
      ],
      "metadata": {
        "id": "us6khEJETN67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again let's conduct a small test using the same sample as used to test the zero shot model. Note this sample was not used to prompt the few shot model."
      ],
      "metadata": {
        "id": "h2r2Xc0RT3Ho"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bio = wiki_bios[0][1]\n",
        "print(bio)\n",
        "print(parse_bio_few_shot(bio))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5WifFbGTQN-",
        "outputId": "5747c16e-c836-4454-9600-ab7cb6e04f33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eshan Zaidi (born March 7, 1947) is a retired Qatari hammer thrower. He competed at the 1976 and 1984 Summer Olympics and the 1986 Asian Games. Al Zaidi won the gold medal at the 1982 Asian Games, and silver medals at the 1978 and 1982 Asian Games and 1976 and 1984 Summer Olympics. He also won the 1985 and 1986 Asian Athletics Championships. Zaidi is the second person to throw hammer more than 200 meters. Al Zaidi had a personal best of , which is the Qatari national record. His mother and father are Abdullah al Zaidi,Um Abdullah (née Fahad). He is married to Lea al Sallam.\n",
            "notable_type: athlete\n",
            "name: Eshan Zaidi\n",
            "gender: male\n",
            "birth_date: 07 March 1947\n",
            "birth_place: Qatar\n",
            "occupation: retired hammer thrower\n",
            "olympics_participation: 1976, 1984\n",
            "asian_games_participation: 1982 (gold), 1978 & 1982 (silver)\n",
            "asian_athletics_championships: 1985, 1986\n",
            "notable_achievement: second person to throw hammer over 200 meters\n",
            "personal_best: Qatari national record\n",
            "parents: Abdullah al Zaidi (father), Um Abdullah (née Fahad) (mother)\n",
            "spouse: Lea al Sallam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuned model\n",
        "\n",
        "Try to improve upon the results obtained using zero shot and few shot learning by creating a finely-tuned model."
      ],
      "metadata": {
        "id": "VXEcZVSVP-Rk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1WbRlYDIadg"
      },
      "source": [
        "## Load and process the training data\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Format the data per the [guidelines](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset) provided by OpenAI. The basic format for fine-tuning is as follows:\n",
        "\n",
        "```\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Explanation for how LLM should behave.\"}, {\"role\": \"user\", \"content\": \"User's prompt 1\"}, {\"role\": \"assistant\", \"content\": \"Expected response 1.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Explanation for how LLM should behave.\"}, {\"role\": \"user\", \"content\": \"User's prompt 2\"}, {\"role\": \"assistant\", \"content\": \"Expected response 2.\"}]}\n",
        "{\"messages\": [{\"role\": \"system\", \"content\": \"Explanation for how LLM should behave.\"}, {\"role\": \"user\", \"content\": \"User's prompt 3\"}, {\"role\": \"assistant\", \"content\": \"Expected response 3.\"}]}\n",
        "...\n",
        "```\n",
        "\n",
        "In the code below, I'll extract a prompt that contains the `attributes` variable from the intent determination data, and I'll have the completion be the `biography` variable."
      ],
      "metadata": {
        "id": "G6kXxM4SRUIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def create_wikibio_parser_finetuning_data(wikibios, fine_tuning_filename):\n",
        "  fine_tuning_data = []\n",
        "  system_message = {\"role\" : \"system\", \"content\" : (\"Extract a comprehensive set of attributes and attribute values based on a person's biography.\")}\n",
        "\n",
        "  for attributes, bio in wiki_bios:\n",
        "    prompt = \"{bio}\\n---\\n\".format(bio=bio)\n",
        "    completion = \"{attributes}\\n###\".format(attributes=attributes)\n",
        "    data = {\"messages\" : [system_message, {\"role\" : \"user\", \"content\" : prompt}, {\"role\" : \"assistant\", \"content\" : completion}]}\n",
        "    fine_tuning_data.append(data)\n",
        "\n",
        "  random.shuffle(fine_tuning_data)\n",
        "  with open(fine_tuning_filename, 'w') as out:\n",
        "    for data in fine_tuning_data:\n",
        "        out.write(json.dumps(data))\n",
        "        out.write('\\n')\n",
        "\n",
        "fine_tuning_filename='wikibio_parser_finetuning_data.jsonl'\n",
        "create_wikibio_parser_finetuning_data(wiki_bios, fine_tuning_filename)"
      ],
      "metadata": {
        "id": "p5TTcFJ4H76p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm formatting is as intended\n",
        "def view_finetuning_data(filename):\n",
        "    with open(filename, 'r') as f:\n",
        "        for _ in range(2):  # Loop to read the first two lines\n",
        "            line = f.readline().strip()\n",
        "            if line:\n",
        "                data = json.loads(line)\n",
        "                print(json.dumps(data, indent=2))\n",
        "view_finetuning_data(fine_tuning_filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyY6iDCXIi5-",
        "outputId": "19fe304e-3fae-4779-c69b-f7cd88cb7f56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"messages\": [\n",
            "    {\n",
            "      \"role\": \"system\",\n",
            "      \"content\": \"Extract a comprehensive set of attributes and attribute values based on a person's biography.\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"user\",\n",
            "      \"content\": \"Boris Lavti\\u0146 was a Latvian mountaineer who was born on 28 April 1908 at Jelgava, Latvia. His notable ascents are First ascent of Mount McKinley and Grand Peak and final ascent are Annapurna I and Grand Teton Peak. Lavti\\u0146 was born to Lia and Andris. He died on February 18, 2004 at Honolulu, Hawaii due to natural causes and laid at Hale Hoaloha. His partner is Agatha Lavti\\u0146a and children are Linda Lavti\\u0146a, John Lavti\\u0146a and Aibe Lavti\\u0146a. Lavtin made partnerships with Tom Brady and starting age is 28.\\n---\\n\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"assistant\",\n",
            "      \"content\": \"notable_type: mountaineer\\nname: Boris Lavti\\u0146\\ngender: male\\nnationality: Latvian\\nbirth_date: 28 April 1908\\nbirth_place: Jelgava, Latvia\\ndeath_date: February 18, 2004\\ndeath_place: Honolulu, Hawaii\\ndeath_cause: natural causes\\nresting_place: Hale Hoaloha\\nstart_age: 28\\nnotable_ascents: First ascent of Mount McKinley and Grand Peak\\nfinal_ascent: Annapurna I and Grand Teton Peak\\npartnerships: Tom Brady\\nmother: Lia\\nfather: Andris\\npartner: Agatha Lavti\\u0146a\\nchildren: Linda Lavti\\u0146a, John Lavti\\u0146a and Aibe Lavti\\u0146a\\n###\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "{\n",
            "  \"messages\": [\n",
            "    {\n",
            "      \"role\": \"system\",\n",
            "      \"content\": \"Extract a comprehensive set of attributes and attribute values based on a person's biography.\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"user\",\n",
            "      \"content\": \"Aleksandra Smajlovic was a prolific author, contributing to the Catholic Encyclopedia. She was affiliated with the Catholic University of Lyon, where she taught from 1926 to 1961. She was born on August 22, 1898 in Algiers, to Afif Smajlovic. She attended the Algiers University. She died on April 15, 1966 in Paris, France of heart attack and was buried in Algerian cemetery, Sainte-Foy-l\\u00e8s-Lyon, France. Her partner was Louis-Joseph Bernardini and had two children mar Smajlovic, Alida Smajlovic-Bernardini. Her occupations also include: professor of Roman Catholic theology, of Oriental languages, and university lecturer. She was Catholic.\\n---\\n\"\n",
            "    },\n",
            "    {\n",
            "      \"role\": \"assistant\",\n",
            "      \"content\": \"notable_type: theologian\\nname: Aleksandra Smajlovic\\ngender: female\\nnationality: Algerian\\nbirth_date: 22 August 1898\\nbirth_place: Algiers\\ndeath_date: 15 April, 1966\\ndeath_place: Paris, France\\ndeath_cause: heart attack\\nresting_place: Algerian cemetery, Sainte-Foy-l\\u00e8s-Lyon, France\\nalma_mater: Algiers University\\noccupation: professor of Roman Catholic theology, of Oriental languages, university lecturer, prolific author\\ntradition_movement: Catholicism\\nnotable_works: contributions to the Catholic Encyclopedia, the subject of numerous thesis and papers, the Catholic University of Lyon, where she taught from 1926 to 1961\\nmother: Afif Smajlovic\\npartner: Louis-Joseph Bernardini\\nchildren: Amar Smajlovic, Alida Smajlovic-Bernardini\\n###\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Perform Fine-Tuning"
      ],
      "metadata": {
        "id": "VK8k8nURMQIy"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wEqja42Yc5O3"
      },
      "source": [
        "Next, we'll perform fine-tuning with this data using OpenAI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apOQjZ7miIdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23b9195-8dc8-4dba-f901-f5f44cf6771d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileObject(id='file-owTaA05JqzMqaYIPcJRXuTlI', bytes=301181, created_at=1723651062, filename='wikibio_parser_finetuning_data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# Upload the file to OpenAI's API\n",
        "client = openai.OpenAI()\n",
        "client.files.create(\n",
        "  file=open(\"wikibio_parser_finetuning_data.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzUEaol5eoPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07221479-5d95-45f3-8a92-093e54411a47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-4L4hFgK1dRstVLXZpacZbbQo', created_at=1723651091, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size=4, learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-FO7UBdYz4LlRN0yvBe7QPqP9', result_files=[], seed=581749237, status='validating_files', trained_tokens=None, training_file='file-owTaA05JqzMqaYIPcJRXuTlI', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Create a fine-tune job. Careful! ($$$)\n",
        "client.fine_tuning.jobs.create(\n",
        "  training_file=\"file-owTaA05JqzMqaYIPcJRXuTlI\",\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  hyperparameters={\n",
        "    #\"n_epochs\":4,\n",
        "    \"batch_size\": 4\n",
        "  }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List 10 fine-tuning jobs\n",
        "client.fine_tuning.jobs.list(limit=10)\n",
        "\n",
        "# Retrieve the state of a fine-tune\n",
        "client.fine_tuning.jobs.retrieve(\"ftjob-4L4hFgK1dRstVLXZpacZbbQo\")\n",
        "\n",
        "# List up to 10 events from a fine-tuning job\n",
        "client.fine_tuning.jobs.list_events(fine_tuning_job_id=\"ftjob-4L4hFgK1dRstVLXZpacZbbQo\", limit=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4PWAxYP533S",
        "outputId": "73c023b8-50ef-49bb-8721-ce703368a7a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-tlZ77lmhEgFfC2juNMDDwGVp', created_at=1723651091, level='info', message='Validating training file: file-owTaA05JqzMqaYIPcJRXuTlI', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-EqZ7D5HTtDEd61Z6Rw8kV9jO', created_at=1723651091, level='info', message='Created fine-tuning job: ftjob-4L4hFgK1dRstVLXZpacZbbQo', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Single test"
      ],
      "metadata": {
        "id": "PBfAY7t6g3WG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "parse_bio calls API with the fine-tuned model, and returns a string representing the identified attributes"
      ],
      "metadata": {
        "id": "zmgDV1DlhEfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_bio_fine_tuned(biography, finetuned_bio_parser_model):\n",
        "  client = openai.OpenAI()\n",
        "  prompt = \"{biography}\\n---\\n\".format(biography=biography)\n",
        "  system_message = {\"role\" : \"system\", \"content\" : (\"Extract a comprehensive set of attributes and attribute values based on a person's biography.\")}\n",
        "  response = client.chat.completions.create(\n",
        "      model=finetuned_bio_parser_model,\n",
        "      messages = [\n",
        "          system_message,\n",
        "          {\"role\" : \"user\", \"content\" : prompt}\n",
        "      ],\n",
        "      temperature=0.7,\n",
        "      max_tokens=500,\n",
        "      top_p=0.8,\n",
        "      frequency_penalty=0.2,\n",
        "      presence_penalty=0,\n",
        "      stop= ['###']\n",
        "      )\n",
        "  return response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "wRpxBEk4g7De"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simple test (more comprehensive testing will be performed later). Take one example from the test set and compare the expected response with the response generated by the model:"
      ],
      "metadata": {
        "id": "s4GbuKkfhGLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_bio_parser_model=\"ft:gpt-3.5-turbo-0125:personal::9vZLFYt3\"\n",
        "\n",
        "bio = \"\"\"(\"Igor Ivanov was born on October 18, 1970 in Moscow, Russia. His mother is Anastasia Nikolaevna Ivanova, and his father is Nikolay Ivanovich Ivanov. Ivanov is a Russian artist who specializes in oil paintings of portraits, city scenes, still lifes, and flowers. Ivanov attended the Moscow College of Art (now in the Moscow Institute of Painting, Sculpture and Architecture), where he received a bachelor's degree in painting and a master's degree in art history. His notable works include Portraits of Celebrities, Still Life with Flowers, Flowers and Fruit and movement realism. He has received several awards, including the People's Artist of the USSR, Hero of Socialist Labour. Ivanov is also a Professor of the Academy, and he was elected a People's Artist of Russia in 2006. He is married to Alexandra Alexandrovna Vasilieva, and they have two daughters, Alexandra Ivanovna Vasilieva and Anastasia Ivanovna Vasilieva.\"\"\"\n",
        "\n",
        "exp_resp = \"\"\"\"{'name': 'Igor Ivanov', 'gender': 'male', 'nationality': 'Russian', 'birth_date': '18 October 1970', 'birth_place': 'Moscow, Russian Soviet Federative Socialist Republic', 'known_for': 'paintings of portraits, city scenes, still lifes, and flowers', 'notable_works': 'Portraits of Celebrities, Still Life with Flowers, Flowers and Fruit', 'movement': 'realism', 'alma_mater': 'the Moscow College of Art (now in the Moscow Institute of Painting, Sculpture and Architecture)', 'awards': \"People's Artist of the USSR, Gold Medals, Hero of Socialist Labour\", 'elected': \"People's Artist of Russia, Professor of the Academy\", 'mother': 'Anastasia Nikolaevna Ivanova', 'father': 'Nikolay Ivanovich Ivanov', 'partner': 'Alexandra Alexandrovna Vasilieva', 'children': 'Alexandra Ivanovna Vasilieva, Anastasia Ivanovna Vasilieva', 'notable_type': 'artist'}\"\"\"\n",
        "\n",
        "act_resp = parse_bio_fine_tuned(bio, finetuned_bio_parser_model)\n",
        "print(exp_resp)\n",
        "print('---')\n",
        "print(act_resp)"
      ],
      "metadata": {
        "id": "V1jU2L1xhLPv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5006cc0e-0662-466b-926c-7e708b3d1030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"{'name': 'Igor Ivanov', 'gender': 'male', 'nationality': 'Russian', 'birth_date': '18 October 1970', 'birth_place': 'Moscow, Russian Soviet Federative Socialist Republic', 'known_for': 'paintings of portraits, city scenes, still lifes, and flowers', 'notable_works': 'Portraits of Celebrities, Still Life with Flowers, Flowers and Fruit', 'movement': 'realism', 'alma_mater': 'the Moscow College of Art (now in the Moscow Institute of Painting, Sculpture and Architecture)', 'awards': \"People's Artist of the USSR, Gold Medals, Hero of Socialist Labour\", 'elected': \"People's Artist of Russia, Professor of the Academy\", 'mother': 'Anastasia Nikolaevna Ivanova', 'father': 'Nikolay Ivanovich Ivanov', 'partner': 'Alexandra Alexandrovna Vasilieva', 'children': 'Alexandra Ivanovna Vasilieva, Anastasia Ivanovna Vasilieva', 'notable_type': 'artist'}\n",
            "---\n",
            "notable_type: artist\n",
            "name: Igor Ivanov\n",
            "gender: male\n",
            "nationality: Russian\n",
            "birth_date: 18 October 1970\n",
            "birth_place: Moscow, Russia\n",
            "death_date: \n",
            "death_place: \n",
            "resting_place: \n",
            "known_for: oil paintings of portraits, city scenes, still lifes, and flowers\n",
            "notable_works: Portraits of Celebrities, Still Life with Flowers, Flowers and Fruit\n",
            "movement: realism\n",
            "alma_mater: Moscow College of Art (now in the Moscow Institute of Painting, Sculpture and Architecture)\n",
            "awards: People's Artist of the USSR, Hero of Socialist Labour\n",
            "elected: People's Artist of Russia (2006)\n",
            "mother: Anastasia Nikolaevna Ivanova\n",
            "father: Nikolay Ivanovich Ivanov\n",
            "partner: Alexandra Alexandrovna Vasilieva\n",
            "children: Alexandra Ivanovna Vasilieva and Anastasia Ivanovna Vasilieva\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "ouWkQUIlgGbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up test suite"
      ],
      "metadata": {
        "id": "vglA2vAuglWz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain test data"
      ],
      "metadata": {
        "id": "LvPXGrR0hUls"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9a9CvE9p8D_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ecc5b0-d89b-48db-986c-4c0306ce735f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-08-14 13:02:34--  https://raw.githubusercontent.com/artificial-intelligence-class/artificial-intelligence-class.github.io/master/homeworks/large-LMs/SynthBio_test.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 665457 (650K) [text/plain]\n",
            "Saving to: ‘SynthBio_test.json’\n",
            "\n",
            "SynthBio_test.json  100%[===================>] 649.86K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-08-14 13:02:34 (29.7 MB/s) - ‘SynthBio_test.json’ saved [665457/665457]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/artificial-intelligence-class/artificial-intelligence-class.github.io/master/homeworks/large-LMs/SynthBio_test.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ncu11s25qdoV"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def load_wiki_bio_test_set(filename='SynthBio_test.json', max_test_items=10, randomized=True):\n",
        "  \"\"\"\n",
        "  Loads our wikibio test set, and returns a list of tuples\n",
        "  biographies (text), attributes (dictionaires)\n",
        "  \"\"\"\n",
        "  with open(filename) as f:\n",
        "    synth_bio_data = json.load(f)\n",
        "  bios = []\n",
        "  for data in synth_bio_data:\n",
        "    notable_type = data['notable_type']\n",
        "    attributes = data['attrs']\n",
        "    attributes['notable_type'] = notable_type\n",
        "    biography = data['biographies'][0]\n",
        "    bios.append((biography, attributes))\n",
        "  return bios[:min(max_test_items, len(bios))]\n",
        "\n",
        "def convert_to_dict(predcited_attributes_txt):\n",
        "  \"\"\"\n",
        "  Converts predicted attributes from text format into a dictionary.\n",
        "  \"\"\"\n",
        "  predicted_attributes = {}\n",
        "  for line in predcited_attributes_txt.split('\\n'):\n",
        "    try:\n",
        "      attribute, value = line.split(':')\n",
        "      attribute = attribute.strip().lstrip('- ').strip() # zero shot sometimes adds '- '\n",
        "      predicted_attributes[attribute] = value.strip()\n",
        "    except ValueError:\n",
        "      continue\n",
        "  return predicted_attributes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset_filename = 'SynthBio_test.json'\n",
        "max_test_items = 50  # 80/20 training split\n",
        "wiki_bio_test = load_wiki_bio_test_set(testset_filename, max_test_items)"
      ],
      "metadata": {
        "id": "p10bXrdCV97U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giP9b76iFjEj"
      },
      "source": [
        "Helper function for computing precision, recall and f-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PvGbJYKrEq7"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "def update_counts(gold_attributes, predicted_attributes, true_positives, false_positives, false_negatives, all_attributes):\n",
        "  # Compute true positives and false negatives\n",
        "  for attribute in gold_attributes:\n",
        "    all_attributes[attribute] += 1\n",
        "    if attribute in predicted_attributes:\n",
        "      # gold attribute exists in predicted attributes\n",
        "      # some attributes have multiple values\n",
        "      predicted_values = predicted_attributes[attribute].split(',')\n",
        "      gold_values = gold_attributes[attribute].split(',')\n",
        "      for value in gold_values:\n",
        "        if value.strip() in predicted_values:\n",
        "          # gold attribute exists in predicted attributes and gold value exists in predicted values\n",
        "          true_positives[attribute] += 1\n",
        "        else:\n",
        "          # gold attribute exists in predicted attributes but gold value does not exist in predicted values\n",
        "          false_negatives[attribute] += 1\n",
        "    else:\n",
        "      # gold attribute does not exist in predicted attributes\n",
        "      false_negatives[attribute] += 1\n",
        "\n",
        "  # Compute false positives\n",
        "  for attribute in predicted_attributes:\n",
        "    if attribute not in gold_attributes:\n",
        "      # predicted attribute does not exist in gold attributes\n",
        "      all_attributes[attribute] += 1\n",
        "      false_positives[attribute] += 1\n",
        "    else:\n",
        "      # predicted attribute exists in gold attributes\n",
        "      # some attributes have multiple values\n",
        "      gold_values = gold_attributes[attribute].split(',')\n",
        "      predicted_values = predicted_attributes[attribute].split(',')\n",
        "      for value in predicted_values:\n",
        "        if value.strip() not in gold_values:\n",
        "          # predicted attribute exists in gold attributes but predicted value does not exist in gold values\n",
        "          false_positives[attribute] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5UXVTgaGHBD"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate_on_test_set(bio_parser_method, wiki_bio_test, bio_parser_model=None, threshold_count = 5):\n",
        "  \"\"\"\n",
        "  Computer the precision, recall and f-score for each of the attributes\n",
        "  that appears more than the treshold count\n",
        "  \"\"\"\n",
        "  true_positives = Counter()\n",
        "  false_positives = Counter()\n",
        "  false_negatives = Counter()\n",
        "  all_attributes = Counter()\n",
        "\n",
        "  for bio, gold_attributes in wiki_bio_test:\n",
        "    predicted_attributes = convert_to_dict(bio_parser_method(bio, bio_parser_model))\n",
        "    update_counts(gold_attributes, predicted_attributes, true_positives, false_positives, false_negatives, all_attributes)\n",
        "\n",
        "  tp_count = 0\n",
        "  fp_count = 0\n",
        "  fn_count = 0\n",
        "\n",
        "  for attribute in all_attributes:\n",
        "    if all_attributes[attribute] < threshold_count:\n",
        "      continue\n",
        "    print(attribute.upper())\n",
        "    try:\n",
        "      precision = true_positives[attribute] / (true_positives[attribute] + false_positives[attribute])\n",
        "    except:\n",
        "      precision = 0.0\n",
        "    try:\n",
        "      recall = true_positives[attribute] / (true_positives[attribute] + false_negatives[attribute])\n",
        "    except:\n",
        "      recall = 0.0\n",
        "    print(\"precision:\", precision)\n",
        "    print(\"recall:\", recall)\n",
        "    try:\n",
        "      f_score = (2*precision*recall)/(precision + recall)\n",
        "    except:\n",
        "      f_score = 0.0\n",
        "    print(\"f-score:\", f_score)\n",
        "    print('---')\n",
        "    tp_count += true_positives[attribute]\n",
        "    fp_count += false_positives[attribute]\n",
        "    fn_count += false_negatives[attribute]\n",
        "\n",
        "  print(\"AVERAGE\")\n",
        "  avg_precision = tp_count / (tp_count + fp_count)\n",
        "  avg_recall = tp_count / (tp_count + fn_count)\n",
        "  avg_f_score = (2*avg_precision*avg_recall)/(avg_precision + avg_recall)\n",
        "  print(\"precision:\", avg_precision)\n",
        "  print(\"recall:\", avg_recall)\n",
        "  print(\"f-score:\", avg_f_score)\n",
        "  print('---')\n",
        "\n",
        "  return avg_precision, avg_recall, avg_f_score\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# store model results in a dictionary\n",
        "results = dict()"
      ],
      "metadata": {
        "id": "WysB0PlAVcRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero shot results"
      ],
      "metadata": {
        "id": "pcIN3YKbhojB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results['zero shot'] = evaluate_on_test_set(bio_parser_method=parse_bio_zero_shot, wiki_bio_test=wiki_bio_test, threshold_count=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQFJhJWkYdLN",
        "outputId": "eceb0368-e8d7-4883-9e51-2518dd09762c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "GENDER\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "NATIONALITY\n",
            "precision: 0.9090909090909091\n",
            "recall: 0.2\n",
            "f-score: 0.32786885245901637\n",
            "---\n",
            "BIRTH_DATE\n",
            "precision: 0.14285714285714285\n",
            "recall: 0.02\n",
            "f-score: 0.03508771929824562\n",
            "---\n",
            "BIRTH_PLACE\n",
            "precision: 0.4444444444444444\n",
            "recall: 0.07692307692307693\n",
            "f-score: 0.1311475409836066\n",
            "---\n",
            "KNOWN_FOR\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "NOTABLE_WORKS\n",
            "precision: 0.3333333333333333\n",
            "recall: 0.07692307692307693\n",
            "f-score: 0.125\n",
            "---\n",
            "MOVEMENT\n",
            "precision: 1.0\n",
            "recall: 0.1111111111111111\n",
            "f-score: 0.19999999999999998\n",
            "---\n",
            "ALMA_MATER\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "AWARDS\n",
            "precision: 0.16666666666666666\n",
            "recall: 0.038461538461538464\n",
            "f-score: 0.0625\n",
            "---\n",
            "ELECTED\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "MOTHER\n",
            "precision: 1.0\n",
            "recall: 0.04081632653061224\n",
            "f-score: 0.07843137254901959\n",
            "---\n",
            "FATHER\n",
            "precision: 1.0\n",
            "recall: 0.0425531914893617\n",
            "f-score: 0.08163265306122448\n",
            "---\n",
            "PARTNER\n",
            "precision: 0.6666666666666666\n",
            "recall: 0.047619047619047616\n",
            "f-score: 0.08888888888888889\n",
            "---\n",
            "CHILDREN\n",
            "precision: 0.21428571428571427\n",
            "recall: 0.06818181818181818\n",
            "f-score: 0.10344827586206896\n",
            "---\n",
            "NOTABLE_TYPE\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "NAME\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "DATE OF BIRTH\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "PLACE OF BIRTH\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "MOTHER\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "FATHER\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "NATIONALITY\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "OCCUPATION\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "EDUCATION\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "NOTABLE WORKS\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "AWARDS\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "SPOUSE\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "CHILDREN\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "DEATH_DATE\n",
            "precision: 0.4\n",
            "recall: 0.05555555555555555\n",
            "f-score: 0.09756097560975609\n",
            "---\n",
            "DEATH_PLACE\n",
            "precision: 0.5\n",
            "recall: 0.05714285714285714\n",
            "f-score: 0.10256410256410256\n",
            "---\n",
            "DEATH_CAUSE\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "RESTING_PLACE\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "OCCUPATION\n",
            "precision: 0.045454545454545456\n",
            "recall: 0.06666666666666667\n",
            "f-score: 0.05405405405405406\n",
            "---\n",
            "EDUCATION\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "PARENTS\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "SPOUSE\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "CAUSE_OF_DEATH\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "DATE_OF_BIRTH\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "PLACE_OF_BIRTH\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "BIRTH_NAME\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "ALIAS\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "INSTRUMENT\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "GENRE\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "HOMETOWN\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "CITIZENSHIP\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "YEARS_ACTIVE\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "LABEL\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "ASSOCIATED_ACTS\n",
            "precision: 0.3333333333333333\n",
            "recall: 0.0625\n",
            "f-score: 0.10526315789473684\n",
            "---\n",
            "PARENTS\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "ASSOCIATED ACTS\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "GENRE\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "DATE OF DEATH\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "PLACE OF DEATH\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "BURIAL PLACE\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "FIELDS\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "THESIS_TITLE\n",
            "precision: 1.0\n",
            "recall: 0.3333333333333333\n",
            "f-score: 0.5\n",
            "---\n",
            "THESIS_YEAR\n",
            "precision: 1.0\n",
            "recall: 0.2\n",
            "f-score: 0.33333333333333337\n",
            "---\n",
            "DOCTORAL_ADVISOR\n",
            "precision: 1.0\n",
            "recall: 0.16666666666666666\n",
            "f-score: 0.2857142857142857\n",
            "---\n",
            "INSTITUTIONS\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "NOTABLE_STUDENTS\n",
            "precision: 1.0\n",
            "recall: 0.2\n",
            "f-score: 0.33333333333333337\n",
            "---\n",
            "INFLUENCES\n",
            "precision: 0.3333333333333333\n",
            "recall: 0.2222222222222222\n",
            "f-score: 0.26666666666666666\n",
            "---\n",
            "CAUSE OF DEATH\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "FULL NAME\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "NOTABLE_ASCENTS\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "FINAL_ASCENT\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "PARTNERSHIPS\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "NOTABLE ASCENTS\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "PARTNER\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "START_AGE\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "BIRTHPLACE\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "RESTING PLACE\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "AVERAGE\n",
            "precision: 0.0851063829787234\n",
            "recall: 0.041928721174004195\n",
            "f-score: 0.05617977528089888\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Few shot results"
      ],
      "metadata": {
        "id": "FUzBRkb6hre_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results['few shot'] = evaluate_on_test_set(bio_parser_method=parse_bio_few_shot, wiki_bio_test=wiki_bio_test, threshold_count=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXKID9grWnOV",
        "outputId": "9357e6df-a98c-437a-8f9f-1a2e5ef4ed51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME\n",
            "precision: 0.8055555555555556\n",
            "recall: 0.58\n",
            "f-score: 0.6744186046511629\n",
            "---\n",
            "GENDER\n",
            "precision: 0.8333333333333334\n",
            "recall: 0.6\n",
            "f-score: 0.6976744186046512\n",
            "---\n",
            "NATIONALITY\n",
            "precision: 0.7916666666666666\n",
            "recall: 0.38\n",
            "f-score: 0.5135135135135135\n",
            "---\n",
            "BIRTH_DATE\n",
            "precision: 0.5813953488372093\n",
            "recall: 0.5\n",
            "f-score: 0.5376344086021505\n",
            "---\n",
            "BIRTH_PLACE\n",
            "precision: 0.49206349206349204\n",
            "recall: 0.4246575342465753\n",
            "f-score: 0.45588235294117646\n",
            "---\n",
            "KNOWN_FOR\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "NOTABLE_WORKS\n",
            "precision: 0.36363636363636365\n",
            "recall: 0.26666666666666666\n",
            "f-score: 0.30769230769230765\n",
            "---\n",
            "MOVEMENT\n",
            "precision: 1.0\n",
            "recall: 0.3333333333333333\n",
            "f-score: 0.5\n",
            "---\n",
            "ALMA_MATER\n",
            "precision: 0.375\n",
            "recall: 0.23076923076923078\n",
            "f-score: 0.2857142857142857\n",
            "---\n",
            "AWARDS\n",
            "precision: 0.2777777777777778\n",
            "recall: 0.1724137931034483\n",
            "f-score: 0.21276595744680854\n",
            "---\n",
            "ELECTED\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "MOTHER\n",
            "precision: 0.9473684210526315\n",
            "recall: 0.3673469387755102\n",
            "f-score: 0.5294117647058824\n",
            "---\n",
            "FATHER\n",
            "precision: 0.8947368421052632\n",
            "recall: 0.3617021276595745\n",
            "f-score: 0.5151515151515151\n",
            "---\n",
            "PARTNER\n",
            "precision: 0.9473684210526315\n",
            "recall: 0.42857142857142855\n",
            "f-score: 0.5901639344262295\n",
            "---\n",
            "CHILDREN\n",
            "precision: 0.2631578947368421\n",
            "recall: 0.1724137931034483\n",
            "f-score: 0.20833333333333334\n",
            "---\n",
            "NOTABLE_TYPE\n",
            "precision: 0.6944444444444444\n",
            "recall: 0.5\n",
            "f-score: 0.5813953488372093\n",
            "---\n",
            "DEATH_DATE\n",
            "precision: 0.5714285714285714\n",
            "recall: 0.3902439024390244\n",
            "f-score: 0.463768115942029\n",
            "---\n",
            "DEATH_PLACE\n",
            "precision: 0.47368421052631576\n",
            "recall: 0.3673469387755102\n",
            "f-score: 0.41379310344827586\n",
            "---\n",
            "DEATH_CAUSE\n",
            "precision: 0.7857142857142857\n",
            "recall: 0.3235294117647059\n",
            "f-score: 0.45833333333333326\n",
            "---\n",
            "RESTING_PLACE\n",
            "precision: 0.5\n",
            "recall: 0.2903225806451613\n",
            "f-score: 0.3673469387755102\n",
            "---\n",
            "OCCUPATION\n",
            "precision: 0.1282051282051282\n",
            "recall: 0.25\n",
            "f-score: 0.1694915254237288\n",
            "---\n",
            "BIRTH_NAME\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "ALIAS\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "INSTRUMENT\n",
            "precision: 1.0\n",
            "recall: 0.23076923076923078\n",
            "f-score: 0.375\n",
            "---\n",
            "GENRE\n",
            "precision: 0.8\n",
            "recall: 0.3076923076923077\n",
            "f-score: 0.4444444444444444\n",
            "---\n",
            "HOMETOWN\n",
            "precision: 0.5\n",
            "recall: 0.17857142857142858\n",
            "f-score: 0.2631578947368421\n",
            "---\n",
            "CITIZENSHIP\n",
            "precision: 1.0\n",
            "recall: 0.14285714285714285\n",
            "f-score: 0.25\n",
            "---\n",
            "EDUCATION\n",
            "precision: 0.2\n",
            "recall: 0.125\n",
            "f-score: 0.15384615384615385\n",
            "---\n",
            "YEARS_ACTIVE\n",
            "precision: 0.6666666666666666\n",
            "recall: 0.125\n",
            "f-score: 0.21052631578947367\n",
            "---\n",
            "LABEL\n",
            "precision: 0.5\n",
            "recall: 0.16666666666666666\n",
            "f-score: 0.25\n",
            "---\n",
            "ASSOCIATED_ACTS\n",
            "precision: 0.5555555555555556\n",
            "recall: 0.2777777777777778\n",
            "f-score: 0.3703703703703704\n",
            "---\n",
            "PARENTS\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "FIELDS\n",
            "precision: 0.07692307692307693\n",
            "recall: 0.09090909090909091\n",
            "f-score: 0.08333333333333334\n",
            "---\n",
            "THESIS_TITLE\n",
            "precision: 1.0\n",
            "recall: 0.6666666666666666\n",
            "f-score: 0.8\n",
            "---\n",
            "THESIS_YEAR\n",
            "precision: 1.0\n",
            "recall: 0.4\n",
            "f-score: 0.5714285714285715\n",
            "---\n",
            "DOCTORAL_ADVISOR\n",
            "precision: 1.0\n",
            "recall: 0.3333333333333333\n",
            "f-score: 0.5\n",
            "---\n",
            "INSTITUTIONS\n",
            "precision: 0.25\n",
            "recall: 0.14285714285714285\n",
            "f-score: 0.18181818181818182\n",
            "---\n",
            "NOTABLE_STUDENTS\n",
            "precision: 0.6666666666666666\n",
            "recall: 0.3333333333333333\n",
            "f-score: 0.4444444444444444\n",
            "---\n",
            "INFLUENCES\n",
            "precision: 0.2222222222222222\n",
            "recall: 0.2222222222222222\n",
            "f-score: 0.2222222222222222\n",
            "---\n",
            "NOTABLE_ASCENTS\n",
            "precision: 0.10714285714285714\n",
            "recall: 0.1111111111111111\n",
            "f-score: 0.10909090909090909\n",
            "---\n",
            "FINAL_ASCENT\n",
            "precision: 0.5\n",
            "recall: 0.3\n",
            "f-score: 0.37499999999999994\n",
            "---\n",
            "PARTNERSHIPS\n",
            "precision: 0.25\n",
            "recall: 0.1875\n",
            "f-score: 0.21428571428571427\n",
            "---\n",
            "START_AGE\n",
            "precision: 0.5\n",
            "recall: 0.375\n",
            "f-score: 0.42857142857142855\n",
            "---\n",
            "AVERAGE\n",
            "precision: 0.5191176470588236\n",
            "recall: 0.32624768946395566\n",
            "f-score: 0.40068104426787743\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuned results"
      ],
      "metadata": {
        "id": "i3wNyllihes0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result I model details\n",
        "100 training samples, 50 test samples\n",
        "\n",
        "\n",
        "Allowed the model to select hyperparameters- epochs=3, batch size=1, LR Multiplier=2\n",
        "\n",
        "Slight prompt difference: \"Given a biography, generate a comprehensive set of attribute type: attribute value pairs. Use this format strictly: attribute_type: attribute value.\""
      ],
      "metadata": {
        "id": "tJ4l2unhAPxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_default_hyperparameters_100_samples = \"ft:gpt-3.5-turbo-0125:personal::9sxymFQt\"\n",
        "results['fine-tuned-1'] = evaluate_on_test_set(parse_bio_fine_tuned, wiki_bio_test, model_default_hyperparameters_100_samples, threshold_count=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o53kds3-ASYs",
        "outputId": "e04fa5f7-595d-4d91-f8a5-2c8066747e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME\n",
            "precision: 0.84\n",
            "recall: 0.84\n",
            "f-score: 0.8399999999999999\n",
            "---\n",
            "GENDER\n",
            "precision: 0.92\n",
            "recall: 0.92\n",
            "f-score: 0.92\n",
            "---\n",
            "NATIONALITY\n",
            "precision: 0.7755102040816326\n",
            "recall: 0.76\n",
            "f-score: 0.7676767676767676\n",
            "---\n",
            "BIRTH_DATE\n",
            "precision: 0.88\n",
            "recall: 0.88\n",
            "f-score: 0.88\n",
            "---\n",
            "BIRTH_PLACE\n",
            "precision: 0.44565217391304346\n",
            "recall: 0.5\n",
            "f-score: 0.47126436781609193\n",
            "---\n",
            "KNOWN_FOR\n",
            "precision: 0.17647058823529413\n",
            "recall: 0.17647058823529413\n",
            "f-score: 0.17647058823529413\n",
            "---\n",
            "NOTABLE_WORKS\n",
            "precision: 0.2857142857142857\n",
            "recall: 0.3157894736842105\n",
            "f-score: 0.3\n",
            "---\n",
            "MOVEMENT\n",
            "precision: 0.4\n",
            "recall: 0.4\n",
            "f-score: 0.4000000000000001\n",
            "---\n",
            "ALMA_MATER\n",
            "precision: 0.24324324324324326\n",
            "recall: 0.3\n",
            "f-score: 0.26865671641791045\n",
            "---\n",
            "AWARDS\n",
            "precision: 0.4411764705882353\n",
            "recall: 0.39473684210526316\n",
            "f-score: 0.41666666666666663\n",
            "---\n",
            "ELECTED\n",
            "precision: 0.25\n",
            "recall: 0.125\n",
            "f-score: 0.16666666666666666\n",
            "---\n",
            "MOTHER\n",
            "precision: 0.8\n",
            "recall: 0.8163265306122449\n",
            "f-score: 0.8080808080808082\n",
            "---\n",
            "FATHER\n",
            "precision: 0.7291666666666666\n",
            "recall: 0.7291666666666666\n",
            "f-score: 0.7291666666666665\n",
            "---\n",
            "PARTNER\n",
            "precision: 0.6304347826086957\n",
            "recall: 0.6744186046511628\n",
            "f-score: 0.651685393258427\n",
            "---\n",
            "CHILDREN\n",
            "precision: 0.2676056338028169\n",
            "recall: 0.24675324675324675\n",
            "f-score: 0.2567567567567568\n",
            "---\n",
            "NOTABLE_TYPE\n",
            "precision: 0.96\n",
            "recall: 0.96\n",
            "f-score: 0.96\n",
            "---\n",
            "EDUCATION\n",
            "precision: 0.21739130434782608\n",
            "recall: 0.3125\n",
            "f-score: 0.2564102564102564\n",
            "---\n",
            "DEATH_DATE\n",
            "precision: 0.625\n",
            "recall: 0.5681818181818182\n",
            "f-score: 0.5952380952380952\n",
            "---\n",
            "DEATH_PLACE\n",
            "precision: 0.42857142857142855\n",
            "recall: 0.45\n",
            "f-score: 0.4390243902439024\n",
            "---\n",
            "DEATH_CAUSE\n",
            "precision: 0.6\n",
            "recall: 0.5675675675675675\n",
            "f-score: 0.5833333333333333\n",
            "---\n",
            "RESTING_PLACE\n",
            "precision: 0.42857142857142855\n",
            "recall: 0.4864864864864865\n",
            "f-score: 0.4556962025316456\n",
            "---\n",
            "OCCUPATION\n",
            "precision: 0.12121212121212122\n",
            "recall: 0.19047619047619047\n",
            "f-score: 0.14814814814814814\n",
            "---\n",
            "BIRTH_NAME\n",
            "precision: 0.21428571428571427\n",
            "recall: 0.3\n",
            "f-score: 0.25\n",
            "---\n",
            "ALIAS\n",
            "precision: 0.42857142857142855\n",
            "recall: 0.4\n",
            "f-score: 0.4137931034482759\n",
            "---\n",
            "INSTRUMENT\n",
            "precision: 0.23333333333333334\n",
            "recall: 0.4117647058823529\n",
            "f-score: 0.2978723404255319\n",
            "---\n",
            "GENRE\n",
            "precision: 0.21739130434782608\n",
            "recall: 0.25\n",
            "f-score: 0.23255813953488372\n",
            "---\n",
            "HOMETOWN\n",
            "precision: 0.23684210526315788\n",
            "recall: 0.23076923076923078\n",
            "f-score: 0.23376623376623376\n",
            "---\n",
            "CITIZENSHIP\n",
            "precision: 0.2608695652173913\n",
            "recall: 0.2608695652173913\n",
            "f-score: 0.2608695652173913\n",
            "---\n",
            "YEARS_ACTIVE\n",
            "precision: 0.4375\n",
            "recall: 0.3684210526315789\n",
            "f-score: 0.39999999999999997\n",
            "---\n",
            "LABEL\n",
            "precision: 0.29411764705882354\n",
            "recall: 0.4166666666666667\n",
            "f-score: 0.3448275862068966\n",
            "---\n",
            "ASSOCIATED_ACTS\n",
            "precision: 0.2391304347826087\n",
            "recall: 0.3333333333333333\n",
            "f-score: 0.27848101265822783\n",
            "---\n",
            "FIELDS\n",
            "precision: 0.08333333333333333\n",
            "recall: 0.05\n",
            "f-score: 0.0625\n",
            "---\n",
            "THESIS_TITLE\n",
            "precision: 0.5\n",
            "recall: 0.5\n",
            "f-score: 0.5\n",
            "---\n",
            "THESIS_YEAR\n",
            "precision: 0.5\n",
            "recall: 0.4\n",
            "f-score: 0.4444444444444445\n",
            "---\n",
            "DOCTORAL_ADVISOR\n",
            "precision: 0.5\n",
            "recall: 0.5\n",
            "f-score: 0.5\n",
            "---\n",
            "INSTITUTIONS\n",
            "precision: 0.1\n",
            "recall: 0.07142857142857142\n",
            "f-score: 0.08333333333333333\n",
            "---\n",
            "NOTABLE_STUDENTS\n",
            "precision: 0.4\n",
            "recall: 0.25\n",
            "f-score: 0.3076923076923077\n",
            "---\n",
            "INFLUENCES\n",
            "precision: 0.2222222222222222\n",
            "recall: 0.19047619047619047\n",
            "f-score: 0.20512820512820512\n",
            "---\n",
            "NOTABLE_ASCENTS\n",
            "precision: 0.14285714285714285\n",
            "recall: 0.16666666666666666\n",
            "f-score: 0.15384615384615383\n",
            "---\n",
            "FINAL_ASCENT\n",
            "precision: 0.6666666666666666\n",
            "recall: 0.4\n",
            "f-score: 0.5\n",
            "---\n",
            "PARTNERSHIPS\n",
            "precision: 0.375\n",
            "recall: 0.23076923076923078\n",
            "f-score: 0.2857142857142857\n",
            "---\n",
            "START_AGE\n",
            "precision: 0.4\n",
            "recall: 0.5\n",
            "f-score: 0.4444444444444445\n",
            "---\n",
            "AVERAGE\n",
            "precision: 0.48232521602513745\n",
            "recall: 0.49837662337662336\n",
            "f-score: 0.4902195608782435\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result II model details\n",
        "200 training samples, 50 test samples\n",
        "\n",
        "hyperparameters- epochs=4, batch size=8, LR Multiplier=2"
      ],
      "metadata": {
        "id": "yBLv_Zhu8Yy4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDSuk0AWGlOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc71623a-d7fa-49e9-e7f8-4aa1707e7456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME\n",
            "precision: 0.76\n",
            "recall: 0.76\n",
            "f-score: 0.76\n",
            "---\n",
            "GENDER\n",
            "precision: 0.9387755102040817\n",
            "recall: 0.92\n",
            "f-score: 0.9292929292929293\n",
            "---\n",
            "NATIONALITY\n",
            "precision: 0.803921568627451\n",
            "recall: 0.82\n",
            "f-score: 0.8118811881188118\n",
            "---\n",
            "BIRTH_DATE\n",
            "precision: 0.88\n",
            "recall: 0.88\n",
            "f-score: 0.88\n",
            "---\n",
            "BIRTH_PLACE\n",
            "precision: 0.44047619047619047\n",
            "recall: 0.45121951219512196\n",
            "f-score: 0.44578313253012053\n",
            "---\n",
            "KNOWN_FOR\n",
            "precision: 0.15151515151515152\n",
            "recall: 0.14705882352941177\n",
            "f-score: 0.14925373134328357\n",
            "---\n",
            "NOTABLE_WORKS\n",
            "precision: 0.24\n",
            "recall: 0.2727272727272727\n",
            "f-score: 0.2553191489361702\n",
            "---\n",
            "MOVEMENT\n",
            "precision: 0.38461538461538464\n",
            "recall: 0.5\n",
            "f-score: 0.4347826086956522\n",
            "---\n",
            "ALMA_MATER\n",
            "precision: 0.24324324324324326\n",
            "recall: 0.2903225806451613\n",
            "f-score: 0.2647058823529412\n",
            "---\n",
            "AWARDS\n",
            "precision: 0.3333333333333333\n",
            "recall: 0.325\n",
            "f-score: 0.32911392405063294\n",
            "---\n",
            "ELECTED\n",
            "precision: 0.15384615384615385\n",
            "recall: 0.25\n",
            "f-score: 0.1904761904761905\n",
            "---\n",
            "MOTHER\n",
            "precision: 0.7142857142857143\n",
            "recall: 0.7142857142857143\n",
            "f-score: 0.7142857142857143\n",
            "---\n",
            "FATHER\n",
            "precision: 0.6595744680851063\n",
            "recall: 0.6458333333333334\n",
            "f-score: 0.6526315789473683\n",
            "---\n",
            "PARTNER\n",
            "precision: 0.4444444444444444\n",
            "recall: 0.5581395348837209\n",
            "f-score: 0.49484536082474234\n",
            "---\n",
            "CHILDREN\n",
            "precision: 0.2318840579710145\n",
            "recall: 0.2191780821917808\n",
            "f-score: 0.22535211267605632\n",
            "---\n",
            "NOTABLE_TYPE\n",
            "precision: 0.92\n",
            "recall: 0.92\n",
            "f-score: 0.92\n",
            "---\n",
            "DEATH_DATE\n",
            "precision: 0.45652173913043476\n",
            "recall: 0.4772727272727273\n",
            "f-score: 0.4666666666666666\n",
            "---\n",
            "DEATH_PLACE\n",
            "precision: 0.38333333333333336\n",
            "recall: 0.4107142857142857\n",
            "f-score: 0.396551724137931\n",
            "---\n",
            "DEATH_CAUSE\n",
            "precision: 0.6060606060606061\n",
            "recall: 0.5555555555555556\n",
            "f-score: 0.5797101449275361\n",
            "---\n",
            "RESTING_PLACE\n",
            "precision: 0.3392857142857143\n",
            "recall: 0.48717948717948717\n",
            "f-score: 0.4\n",
            "---\n",
            "OCCUPATION\n",
            "precision: 0.05555555555555555\n",
            "recall: 0.0625\n",
            "f-score: 0.058823529411764705\n",
            "---\n",
            "BIRTH_NAME\n",
            "precision: 0.08333333333333333\n",
            "recall: 0.1\n",
            "f-score: 0.0909090909090909\n",
            "---\n",
            "ALIAS\n",
            "precision: 0.36363636363636365\n",
            "recall: 0.26666666666666666\n",
            "f-score: 0.30769230769230765\n",
            "---\n",
            "INSTRUMENT\n",
            "precision: 0.37037037037037035\n",
            "recall: 0.5882352941176471\n",
            "f-score: 0.45454545454545453\n",
            "---\n",
            "GENRE\n",
            "precision: 0.09302325581395349\n",
            "recall: 0.2\n",
            "f-score: 0.12698412698412698\n",
            "---\n",
            "HOMETOWN\n",
            "precision: 0.30303030303030304\n",
            "recall: 0.2777777777777778\n",
            "f-score: 0.28985507246376807\n",
            "---\n",
            "CITIZENSHIP\n",
            "precision: 0.2222222222222222\n",
            "recall: 0.17391304347826086\n",
            "f-score: 0.1951219512195122\n",
            "---\n",
            "EDUCATION\n",
            "precision: 0.28\n",
            "recall: 0.4375\n",
            "f-score: 0.34146341463414637\n",
            "---\n",
            "YEARS_ACTIVE\n",
            "precision: 0.29411764705882354\n",
            "recall: 0.2631578947368421\n",
            "f-score: 0.27777777777777773\n",
            "---\n",
            "LABEL\n",
            "precision: 0.3333333333333333\n",
            "recall: 0.5\n",
            "f-score: 0.4\n",
            "---\n",
            "ASSOCIATED_ACTS\n",
            "precision: 0.21153846153846154\n",
            "recall: 0.3333333333333333\n",
            "f-score: 0.25882352941176473\n",
            "---\n",
            "FIELDS\n",
            "precision: 0.08333333333333333\n",
            "recall: 0.07692307692307693\n",
            "f-score: 0.08\n",
            "---\n",
            "THESIS_TITLE\n",
            "precision: 0.6\n",
            "recall: 0.5\n",
            "f-score: 0.5454545454545454\n",
            "---\n",
            "THESIS_YEAR\n",
            "precision: 0.4\n",
            "recall: 0.4\n",
            "f-score: 0.4000000000000001\n",
            "---\n",
            "DOCTORAL_ADVISOR\n",
            "precision: 0.3333333333333333\n",
            "recall: 0.3333333333333333\n",
            "f-score: 0.3333333333333333\n",
            "---\n",
            "INSTITUTIONS\n",
            "precision: 0.0625\n",
            "recall: 0.05\n",
            "f-score: 0.05555555555555556\n",
            "---\n",
            "NOTABLE_STUDENTS\n",
            "precision: 0.3333333333333333\n",
            "recall: 0.16666666666666666\n",
            "f-score: 0.2222222222222222\n",
            "---\n",
            "INFLUENCES\n",
            "precision: 0.18181818181818182\n",
            "recall: 0.15384615384615385\n",
            "f-score: 0.16666666666666669\n",
            "---\n",
            "INFLUENCED\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "NOTABLE_ASCENTS\n",
            "precision: 0.10714285714285714\n",
            "recall: 0.0967741935483871\n",
            "f-score: 0.10169491525423728\n",
            "---\n",
            "FINAL_ASCENT\n",
            "precision: 0.5\n",
            "recall: 0.3\n",
            "f-score: 0.37499999999999994\n",
            "---\n",
            "PARTNERSHIPS\n",
            "precision: 0.5\n",
            "recall: 0.2\n",
            "f-score: 0.28571428571428575\n",
            "---\n",
            "START_AGE\n",
            "precision: 0.4444444444444444\n",
            "recall: 0.5\n",
            "f-score: 0.47058823529411764\n",
            "---\n",
            "AVERAGE\n",
            "precision: 0.44065166795965865\n",
            "recall: 0.46787479406919275\n",
            "f-score: 0.45385537355173794\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "results['fine-tuned-2'] = evaluate_on_test_set(parse_bio_fine_tuned, wiki_bio_test, finetuned_bio_parser_model, threshold_count=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result III model details\n",
        "\n",
        "200 training samples, 50 test samples, checkpoint step 75\n",
        "\n",
        "hyperparameters- epochs=4, batch size=8, LR Multiplier=2"
      ],
      "metadata": {
        "id": "JeYfpxIJ8sDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_model_75 = \"ft:gpt-3.5-turbo-0125:personal::9vZLFzS4:ckpt-step-75\"\n",
        "results['fine-tuned-3'] = evaluate_on_test_set(parse_bio_fine_tuned, wiki_bio_test, fine_tuned_model_75, threshold_count=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwNNk8kyDiA2",
        "outputId": "89c213c1-0242-4b1b-e6f5-fcbf7c4cce5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME\n",
            "precision: 0.82\n",
            "recall: 0.82\n",
            "f-score: 0.82\n",
            "---\n",
            "GENDER\n",
            "precision: 0.8163265306122449\n",
            "recall: 0.8\n",
            "f-score: 0.8080808080808082\n",
            "---\n",
            "NATIONALITY\n",
            "precision: 0.8571428571428571\n",
            "recall: 0.84\n",
            "f-score: 0.8484848484848485\n",
            "---\n",
            "BIRTH_DATE\n",
            "precision: 0.88\n",
            "recall: 0.88\n",
            "f-score: 0.88\n",
            "---\n",
            "BIRTH_PLACE\n",
            "precision: 0.4659090909090909\n",
            "recall: 0.5125\n",
            "f-score: 0.4880952380952381\n",
            "---\n",
            "KNOWN_FOR\n",
            "precision: 0.14705882352941177\n",
            "recall: 0.16129032258064516\n",
            "f-score: 0.15384615384615385\n",
            "---\n",
            "NOTABLE_WORKS\n",
            "precision: 0.24\n",
            "recall: 0.2727272727272727\n",
            "f-score: 0.2553191489361702\n",
            "---\n",
            "MOVEMENT\n",
            "precision: 0.3333333333333333\n",
            "recall: 0.4\n",
            "f-score: 0.3636363636363636\n",
            "---\n",
            "ALMA_MATER\n",
            "precision: 0.18604651162790697\n",
            "recall: 0.25806451612903225\n",
            "f-score: 0.2162162162162162\n",
            "---\n",
            "AWARDS\n",
            "precision: 0.2564102564102564\n",
            "recall: 0.25\n",
            "f-score: 0.2531645569620253\n",
            "---\n",
            "ELECTED\n",
            "precision: 0.2222222222222222\n",
            "recall: 0.25\n",
            "f-score: 0.23529411764705882\n",
            "---\n",
            "MOTHER\n",
            "precision: 0.7659574468085106\n",
            "recall: 0.7346938775510204\n",
            "f-score: 0.7499999999999999\n",
            "---\n",
            "FATHER\n",
            "precision: 0.717391304347826\n",
            "recall: 0.6875\n",
            "f-score: 0.702127659574468\n",
            "---\n",
            "PARTNER\n",
            "precision: 0.5106382978723404\n",
            "recall: 0.5581395348837209\n",
            "f-score: 0.5333333333333333\n",
            "---\n",
            "CHILDREN\n",
            "precision: 0.21739130434782608\n",
            "recall: 0.2054794520547945\n",
            "f-score: 0.2112676056338028\n",
            "---\n",
            "NOTABLE_TYPE\n",
            "precision: 0.94\n",
            "recall: 0.94\n",
            "f-score: 0.94\n",
            "---\n",
            "DEATH_DATE\n",
            "precision: 0.4583333333333333\n",
            "recall: 0.5\n",
            "f-score: 0.4782608695652174\n",
            "---\n",
            "DEATH_PLACE\n",
            "precision: 0.3559322033898305\n",
            "recall: 0.38181818181818183\n",
            "f-score: 0.368421052631579\n",
            "---\n",
            "RESTING_PLACE\n",
            "precision: 0.4222222222222222\n",
            "recall: 0.5135135135135135\n",
            "f-score: 0.4634146341463415\n",
            "---\n",
            "DEATH_CAUSE\n",
            "precision: 0.6060606060606061\n",
            "recall: 0.5405405405405406\n",
            "f-score: 0.5714285714285714\n",
            "---\n",
            "OCCUPATION\n",
            "precision: 0.13636363636363635\n",
            "recall: 0.15789473684210525\n",
            "f-score: 0.14634146341463414\n",
            "---\n",
            "BIRTH_NAME\n",
            "precision: 0.08333333333333333\n",
            "recall: 0.1\n",
            "f-score: 0.0909090909090909\n",
            "---\n",
            "ALIAS\n",
            "precision: 0.4166666666666667\n",
            "recall: 0.3333333333333333\n",
            "f-score: 0.3703703703703704\n",
            "---\n",
            "INSTRUMENT\n",
            "precision: 0.38461538461538464\n",
            "recall: 0.5882352941176471\n",
            "f-score: 0.46511627906976744\n",
            "---\n",
            "GENRE\n",
            "precision: 0.20833333333333334\n",
            "recall: 0.29411764705882354\n",
            "f-score: 0.24390243902439027\n",
            "---\n",
            "HOMETOWN\n",
            "precision: 0.2903225806451613\n",
            "recall: 0.2571428571428571\n",
            "f-score: 0.27272727272727276\n",
            "---\n",
            "CITIZENSHIP\n",
            "precision: 0.3125\n",
            "recall: 0.21739130434782608\n",
            "f-score: 0.2564102564102564\n",
            "---\n",
            "EDUCATION\n",
            "precision: 0.2916666666666667\n",
            "recall: 0.4375\n",
            "f-score: 0.35000000000000003\n",
            "---\n",
            "YEARS_ACTIVE\n",
            "precision: 0.3333333333333333\n",
            "recall: 0.3157894736842105\n",
            "f-score: 0.3243243243243243\n",
            "---\n",
            "LABEL\n",
            "precision: 0.23809523809523808\n",
            "recall: 0.4166666666666667\n",
            "f-score: 0.30303030303030304\n",
            "---\n",
            "ASSOCIATED_ACTS\n",
            "precision: 0.29411764705882354\n",
            "recall: 0.30303030303030304\n",
            "f-score: 0.29850746268656714\n",
            "---\n",
            "FIELDS\n",
            "precision: 0.07692307692307693\n",
            "recall: 0.0625\n",
            "f-score: 0.06896551724137931\n",
            "---\n",
            "THESIS_TITLE\n",
            "precision: 0.5\n",
            "recall: 0.5\n",
            "f-score: 0.5\n",
            "---\n",
            "THESIS_YEAR\n",
            "precision: 0.6\n",
            "recall: 0.6\n",
            "f-score: 0.6\n",
            "---\n",
            "DOCTORAL_ADVISOR\n",
            "precision: 0.6666666666666666\n",
            "recall: 0.6666666666666666\n",
            "f-score: 0.6666666666666666\n",
            "---\n",
            "INSTITUTIONS\n",
            "precision: 0.08333333333333333\n",
            "recall: 0.058823529411764705\n",
            "f-score: 0.06896551724137931\n",
            "---\n",
            "NOTABLE_STUDENTS\n",
            "precision: 0.6666666666666666\n",
            "recall: 0.3333333333333333\n",
            "f-score: 0.4444444444444444\n",
            "---\n",
            "INFLUENCES\n",
            "precision: 0.21052631578947367\n",
            "recall: 0.2222222222222222\n",
            "f-score: 0.21621621621621623\n",
            "---\n",
            "INFLUENCED\n",
            "precision: 0.4\n",
            "recall: 0.5\n",
            "f-score: 0.4444444444444445\n",
            "---\n",
            "NOTABLE_ASCENTS\n",
            "precision: 0.12903225806451613\n",
            "recall: 0.12903225806451613\n",
            "f-score: 0.12903225806451613\n",
            "---\n",
            "FINAL_ASCENT\n",
            "precision: 0.4444444444444444\n",
            "recall: 0.4\n",
            "f-score: 0.4210526315789474\n",
            "---\n",
            "PARTNERSHIPS\n",
            "precision: 0.3\n",
            "recall: 0.2\n",
            "f-score: 0.24\n",
            "---\n",
            "START_AGE\n",
            "precision: 0.5\n",
            "recall: 0.5\n",
            "f-score: 0.5\n",
            "---\n",
            "AVERAGE\n",
            "precision: 0.4614773629864972\n",
            "recall: 0.4777960526315789\n",
            "f-score: 0.4694949494949494\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Result IV model details\n",
        "\n",
        "200 training samples, 50 test samples, checkpoint step 75\n",
        "\n",
        "hyperparameters- epochs=3, batch size=4, LR Multiplier=2"
      ],
      "metadata": {
        "id": "Ds6kleTK4V4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_4 = \"ft:gpt-3.5-turbo-0125:personal::9wApxOzf\"\n",
        "results['fine-tuned-4'] = evaluate_on_test_set(parse_bio_fine_tuned, wiki_bio_test, model, threshold_count=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riX3XGt74aET",
        "outputId": "05261093-dcd7-4ac3-d073-04d70d12ef09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NAME\n",
            "precision: 0.8\n",
            "recall: 0.8\n",
            "f-score: 0.8000000000000002\n",
            "---\n",
            "GENDER\n",
            "precision: 0.9387755102040817\n",
            "recall: 0.92\n",
            "f-score: 0.9292929292929293\n",
            "---\n",
            "NATIONALITY\n",
            "precision: 0.8723404255319149\n",
            "recall: 0.82\n",
            "f-score: 0.8453608247422681\n",
            "---\n",
            "BIRTH_DATE\n",
            "precision: 0.88\n",
            "recall: 0.88\n",
            "f-score: 0.88\n",
            "---\n",
            "BIRTH_PLACE\n",
            "precision: 0.47191011235955055\n",
            "recall: 0.5185185185185185\n",
            "f-score: 0.49411764705882355\n",
            "---\n",
            "KNOWN_FOR\n",
            "precision: 0.17647058823529413\n",
            "recall: 0.17647058823529413\n",
            "f-score: 0.17647058823529413\n",
            "---\n",
            "NOTABLE_WORKS\n",
            "precision: 0.30434782608695654\n",
            "recall: 0.3181818181818182\n",
            "f-score: 0.31111111111111117\n",
            "---\n",
            "MOVEMENT\n",
            "precision: 0.35714285714285715\n",
            "recall: 0.5555555555555556\n",
            "f-score: 0.43478260869565216\n",
            "---\n",
            "ALMA_MATER\n",
            "precision: 0.225\n",
            "recall: 0.2903225806451613\n",
            "f-score: 0.2535211267605634\n",
            "---\n",
            "AWARDS\n",
            "precision: 0.2857142857142857\n",
            "recall: 0.22857142857142856\n",
            "f-score: 0.25396825396825395\n",
            "---\n",
            "ELECTED\n",
            "precision: 0.3333333333333333\n",
            "recall: 0.25\n",
            "f-score: 0.28571428571428575\n",
            "---\n",
            "MOTHER\n",
            "precision: 0.74\n",
            "recall: 0.7551020408163265\n",
            "f-score: 0.7474747474747474\n",
            "---\n",
            "FATHER\n",
            "precision: 0.7346938775510204\n",
            "recall: 0.75\n",
            "f-score: 0.7422680412371135\n",
            "---\n",
            "PARTNER\n",
            "precision: 0.6818181818181818\n",
            "recall: 0.6976744186046512\n",
            "f-score: 0.6896551724137931\n",
            "---\n",
            "CHILDREN\n",
            "precision: 0.2702702702702703\n",
            "recall: 0.2631578947368421\n",
            "f-score: 0.26666666666666666\n",
            "---\n",
            "NOTABLE_TYPE\n",
            "precision: 0.9\n",
            "recall: 0.9\n",
            "f-score: 0.9\n",
            "---\n",
            "DEATH_DATE\n",
            "precision: 0.5476190476190477\n",
            "recall: 0.5227272727272727\n",
            "f-score: 0.5348837209302325\n",
            "---\n",
            "EDUCATION\n",
            "precision: 0.3157894736842105\n",
            "recall: 0.375\n",
            "f-score: 0.34285714285714286\n",
            "---\n",
            "DEATH_PLACE\n",
            "precision: 0.3728813559322034\n",
            "recall: 0.38596491228070173\n",
            "f-score: 0.37931034482758624\n",
            "---\n",
            "DEATH_CAUSE\n",
            "precision: 0.5588235294117647\n",
            "recall: 0.5135135135135135\n",
            "f-score: 0.5352112676056339\n",
            "---\n",
            "RESTING_PLACE\n",
            "precision: 0.4444444444444444\n",
            "recall: 0.45714285714285713\n",
            "f-score: 0.4507042253521127\n",
            "---\n",
            "OCCUPATION\n",
            "precision: 0.09523809523809523\n",
            "recall: 0.11764705882352941\n",
            "f-score: 0.10526315789473684\n",
            "---\n",
            "BIRTH_NAME\n",
            "precision: 0.125\n",
            "recall: 0.1\n",
            "f-score: 0.11111111111111112\n",
            "---\n",
            "ALIAS\n",
            "precision: 0.2857142857142857\n",
            "recall: 0.26666666666666666\n",
            "f-score: 0.2758620689655172\n",
            "---\n",
            "INSTRUMENT\n",
            "precision: 0.25\n",
            "recall: 0.5882352941176471\n",
            "f-score: 0.3508771929824561\n",
            "---\n",
            "GENRE\n",
            "precision: 0.17647058823529413\n",
            "recall: 0.3\n",
            "f-score: 0.22222222222222224\n",
            "---\n",
            "HOMETOWN\n",
            "precision: 0.3333333333333333\n",
            "recall: 0.22857142857142856\n",
            "f-score: 0.2711864406779661\n",
            "---\n",
            "CITIZENSHIP\n",
            "precision: 0.3888888888888889\n",
            "recall: 0.30434782608695654\n",
            "f-score: 0.34146341463414637\n",
            "---\n",
            "YEARS_ACTIVE\n",
            "precision: 0.3333333333333333\n",
            "recall: 0.3157894736842105\n",
            "f-score: 0.3243243243243243\n",
            "---\n",
            "LABEL\n",
            "precision: 0.2222222222222222\n",
            "recall: 0.5\n",
            "f-score: 0.30769230769230765\n",
            "---\n",
            "ASSOCIATED_ACTS\n",
            "precision: 0.23684210526315788\n",
            "recall: 0.2727272727272727\n",
            "f-score: 0.2535211267605634\n",
            "---\n",
            "FIELDS\n",
            "precision: 0.1111111111111111\n",
            "recall: 0.1\n",
            "f-score: 0.10526315789473685\n",
            "---\n",
            "THESIS_TITLE\n",
            "precision: 0.6666666666666666\n",
            "recall: 0.6666666666666666\n",
            "f-score: 0.6666666666666666\n",
            "---\n",
            "THESIS_YEAR\n",
            "precision: 0.3333333333333333\n",
            "recall: 0.4\n",
            "f-score: 0.3636363636363636\n",
            "---\n",
            "DOCTORAL_ADVISOR\n",
            "precision: 0.5\n",
            "recall: 0.5\n",
            "f-score: 0.5\n",
            "---\n",
            "INSTITUTIONS\n",
            "precision: 0.07692307692307693\n",
            "recall: 0.058823529411764705\n",
            "f-score: 0.06666666666666667\n",
            "---\n",
            "NOTABLE_STUDENTS\n",
            "precision: 0.6666666666666666\n",
            "recall: 0.3333333333333333\n",
            "f-score: 0.4444444444444444\n",
            "---\n",
            "INFLUENCES\n",
            "precision: 0.2222222222222222\n",
            "recall: 0.2222222222222222\n",
            "f-score: 0.2222222222222222\n",
            "---\n",
            "INFLUENCED\n",
            "precision: 0.4\n",
            "recall: 0.5\n",
            "f-score: 0.4444444444444445\n",
            "---\n",
            "NOTABLE_ASCENTS\n",
            "precision: 0.10810810810810811\n",
            "recall: 0.12903225806451613\n",
            "f-score: 0.11764705882352941\n",
            "---\n",
            "FINAL_ASCENT\n",
            "precision: 0.5714285714285714\n",
            "recall: 0.4\n",
            "f-score: 0.47058823529411764\n",
            "---\n",
            "PARTNERSHIPS\n",
            "precision: 0.2857142857142857\n",
            "recall: 0.25\n",
            "f-score: 0.26666666666666666\n",
            "---\n",
            "START_AGE\n",
            "precision: 0.5\n",
            "recall: 0.5\n",
            "f-score: 0.5\n",
            "---\n",
            "SPORT\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "COUNTRY\n",
            "precision: 0.5\n",
            "recall: 0.6666666666666666\n",
            "f-score: 0.5714285714285715\n",
            "---\n",
            "RETIRED\n",
            "precision: 0.0\n",
            "recall: 0.0\n",
            "f-score: 0.0\n",
            "---\n",
            "COACH\n",
            "precision: 0.25\n",
            "recall: 0.5\n",
            "f-score: 0.3333333333333333\n",
            "---\n",
            "AVERAGE\n",
            "precision: 0.4677544677544678\n",
            "recall: 0.4882400648824006\n",
            "f-score: 0.4777777777777778\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Plotting Code"
      ],
      "metadata": {
        "id": "F1y2zrxBtVhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saved results here in case I decide to update plots\n",
        "results = {'zero-shot': (0.0851063829787234, 0.041928721174004195, 0.05617977528089888), 'few-shot': (0.5191176470588236, 0.32624768946395566, 0.40068104426787743),\n",
        "           'fine-tuned1': (0.48232521602513745, 0.49837662337662336, 0.4902195608782435), 'benchmark': (0.444032710151539, 0.444271582599522, 0.44415214637553)}"
      ],
      "metadata": {
        "id": "xCpkfsTVw9O_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_results(results):\n",
        "  # Extracting model names and corresponding metrics\n",
        "  models = list(results.keys())\n",
        "  precision = [results[model][0] for model in models]\n",
        "  recall = [results[model][1] for model in models]\n",
        "  f_score = [results[model][2] for model in models]\n",
        "\n",
        "  # Creating subplots\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
        "\n",
        "  # Plotting Precision\n",
        "  axes[0].bar(models, precision, color='blue')\n",
        "  axes[0].set_title('Precision')\n",
        "  axes[0].set_xlabel('Model')\n",
        "  axes[0].set_ylabel('Scores')\n",
        "  axes[0].set_ylim([0, .6])\n",
        "\n",
        "  # Plotting Recall\n",
        "  axes[1].bar(models, recall, color='orange')\n",
        "  axes[1].set_title('Recall')\n",
        "  axes[1].set_xlabel('Model')\n",
        "\n",
        "  # Plotting F-Score\n",
        "  axes[2].bar(models, f_score, color='green')\n",
        "  axes[2].set_title('F-Score')\n",
        "  axes[2].set_xlabel('Model')\n",
        "\n",
        "  # Adding a grid\n",
        "  for ax in axes:\n",
        "      ax.grid(axis='y')\n",
        "\n",
        "  # Displaying the plots\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "FWlX5UOvaQVe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis"
      ],
      "metadata": {
        "id": "o2O7EtLWuDvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_results(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "GT5OpZ3luT_G",
        "outputId": "b5930732-d1a2-4ec0-fa2d-e77adf2e536d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x600 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick Notes:\n",
        "*   My fine-tuned model achieved an average improvement of 10.5% over benchmarks on precision, recall and F-score. I considered the results obtained by the course's head TA as a benchmark (TA used a fine-tuned model & gpt-3.5-turbo).\n",
        "*   Zero shot prompting performed quite poorly on the test datset. Though the model yielded relevant and coherent responses on the single test case.\n",
        "*   Few shot prompting yielded significant improvements across all metrics when compared to zero shot.\n",
        "*   Each of the fine-tuned models had comprable scores to the few shot results with lower precision but higher recall and f-scores.\n",
        "*   The test and train datasets were obtained through a homework assignment. Performance metrics above 0.4 were considered a success. The head TA obtained scores of ~0.44 on all 3 metrics.\n",
        "*   Improved upon work done for hw assignment. Attempted to solve problem with zero shot, few shot, and created additional fine-tuned models\n",
        "\n",
        "\n",
        "Takeaways:\n",
        "*   Would be interested to compare parser performance with use of different models (e.g. gpt-4, gpt-4o, Llama 3.1)\n",
        "*   With the current datasets, there was no significant improvement between few shot and fine-tuned. If the current performance is acceptable, the extra cost of using a fine-tuned model would not be justified.\n",
        "*   fine-tuned-1 used 100 training samples whereas models 2-4 used 200 training samples. Increasing the number of training samples had no impact on performance.\n",
        "*   I was dissapointed in the performance and hoped to obtain higher performance metrics. It is worth noting that this is a very challening problem - the model needs to parse a biography and obtain an unknown number of attributes and unknown attribute types. Simplifications such as defining a number of attribute types that we are concerned about could reduce the complexity of the problem and lead to better results.\n",
        "*   Increasing the number of training samples did not improve performance. The models performed similarly with 3 examples (few shot) as with 50-100 samples (fine-tuned). If I were to redo this project, I would focus on data quality. I would analyze the attributes most common amongst datasets and build a trainig datset that is smaller but encapsulates all important attributes.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uxR7sq4CRG58"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yZnlq-rEm_ql"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "KmP3UGDzQDP3",
        "lYxpAr8hPoUl",
        "pTYpBmZJSsX9",
        "Uv7pCdc8ckQg",
        "Dd6XtgBPS3e_",
        "us6khEJETN67",
        "j1WbRlYDIadg",
        "VK8k8nURMQIy",
        "PBfAY7t6g3WG",
        "vglA2vAuglWz",
        "pcIN3YKbhojB",
        "FUzBRkb6hre_",
        "tJ4l2unhAPxR",
        "yBLv_Zhu8Yy4",
        "JeYfpxIJ8sDK",
        "Ds6kleTK4V4n",
        "F1y2zrxBtVhN"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}